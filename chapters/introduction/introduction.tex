\chapter{Introduction}
\label{ch:introduction}

\todo{Introduction:}
\begin{itemize}
  \item Need for new computational methods (adaptive)
  \item Statistics on usage of FDS? (literatur aus bennis diss?)
  
  \item Latest catastrophes: tower, DÃ¼sseldorf
  \item ... help to .. catastrophes by giving hints on placements of safety measures.
\end{itemize}

Recent advancements in computer technology allows us to solve problems with billions of unknowns. However, raw computing power does not mean we can use it without further ado. The keys to efficiency are algorithms that exploit the hardware structure and focus resources on critical operations.

For currently common multi-processor systems, algorithms for parallelization need to be supplied . These methods depend on the hardware architecture, and especially large-scale supercomputers with distributed memory access benefit from this method.

Lots of \glspl{api} exist for these purposes, that allow users to take opportunity of already implemented ideas.

For machines with shared memory access, \gls{openmp} \textcite{openmp50} and \gls{tbb} \textcite{tbb2018} with its work stealing policy are the most prominent approaches. If architecture is distributed on nodes and thus have distributed memory access, the \gls{mpi} \textcite{mpi31} will be used. A combination of both is possbile.

Further, recently streaming multiprocessor architecture have become more and more interest, that work on graphic accelerator cards (GPUS). \gls{openacc} \textcite{openacc27} or nVidia's \gls{cuda} \textcite{cuda10} can be used for that.

On the other hand, . adaptive

A combinatation of both hardware and .. software driven algorithms can be supplied. However, their combination is not trivial. 

"MPI remains the dominant library for production programming on large scale distributed memory machines."

Some typeof hardware-related 
To name a few, Hardware-related algorithms are parallelization, vectorization and limiting memory access, since it. In terms 


guarantee the full usage of all available resources. The key to use those ausnutzen fully are efficient algorithms that either fit to the hardware or distribute resources on computing intensive operations.

However, the key to use these structures efficientis to , and not computing power alone; (Erst) the combination with algorithms that use these structure efficiently offers a massive potential to reduce 




Some of them

parallelization, vectorization, limit memory access. adaptive methods

parallelization depending on hardware architecture: MPI for distributed memory, OpenMP for shared memory, OpenACC or nVidia CUDA for streaming multiprocessors on e.g. GPUs

adaptive methods to focus .


Each algorithm . The combination of both is more or less trivial.
On supercomputers
This thesis presents the combination of both parallelization on distributed hardware architecture, and hp-adaptive methods.

For spatial discretizations we use . The \gls{fem}


Parallel \hp-adaptive \gls{fem} has been , but always in the context of \gls{dg} methods. For example for Navier-Stokes problems, \textcite{chalmers2019} presented methods for distributed memory architectures, while \textcite{paszynski2011} presented methods for shared memory machines. A general approach that also works with \gls{cg} methods is missing.

However, \hp-adaptive methods have always stayed in an experimental scope and have never been prepared to be easily applied by a broader academic audience, especially in combination with parallelization.

Though there are several open-source libraries that provide the bare functionality for \hp-adaptive \gls{fem} on distributed memory architectures using the \gls{mpi} protocol, namely the libraries \phaml{} \parencites{mitchell2002}{phaml1200}, \phg{} \parencites{zhanglin-bo2019}{phg094}, and \mofem{} \parencites{kaczmarczyk2020}{mofem090}. However, even here the application of these features is not immediately accessible to the end user and it is difficult to make an easy use out of these features.

Further, although parallel \hp-adaptive \glspl{fem} have been presented thoroughly, there is no systematic description on how to realize them yet as a software application. There are publications that highlight all necessary data structures and algorithms parallelization (parallel paper) and \hp-adaptive methods. % todo

The goal of this dissertation is to provide the connection between both algorithms, which highlights difficulties to combine both parallelization with \hp-adaptive methods. This dissertation is not meant to be an in-depth guide for the creation of \gls{fem} software. We would rather like to emphasize on the basic ideas for parallel hp-adaptive \gls{fem} and point out programming challenges. We will provide an example implementation in the \dealii{} library, so that the reader is able to either embed our findings into his own \gls{fem} code or use the \dealii{} implementation right away.

In the \dealii{} library, we rely on third party libraries. Parallel linear algebra by \trilinos{} and \petsc{}.

The whole parallel grid adaptation is done with \pforest{}. While linear algebra with interfaces, we use \pforest{} as an oracle. That means we store a separate copy of the traingulation inside \pforest{} and apply their algorithms on it and then transfer the changes back to the \dealii{} data structures.
